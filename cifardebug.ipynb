{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ram used:  0.00 GB, l2.weight                                         : 100%|██████████| 2/2 [00:00<00:00, 1771.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded weights in 2.65 ms, 0.00 GB loaded at 0.93 GB/s\n",
      "step0 | Loss: 0.07643339037895203 | Accuracy: 0.9765625\n",
      "(10000, 784)\n",
      "(1, 10)\n",
      "1\n",
      "[1]\n",
      "[[  0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "    0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "    0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "    0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "    0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "    0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "    0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "    0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "    0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.  55.\n",
      "  236. 107.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "    0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0. 169.\n",
      "  252. 185.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "    0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.  72.\n",
      "  252. 211.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "    0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.  64.\n",
      "  252. 211.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "    0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.  64.\n",
      "  252. 211.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "    0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.  64.\n",
      "  253. 237.  37.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "    0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.  43.\n",
      "  239. 253.  63.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "    0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "  211. 253.  63.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "    0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "  211. 253.  63.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "    0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "  211. 253.  63.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "    0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "  212. 255.  63.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "    0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "  211. 253.  63.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "    0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   6.\n",
      "  215. 253.  63.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "    0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.  21.\n",
      "  225. 253. 107.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "    0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.  54.\n",
      "  246. 253.  63.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "    0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.  64.\n",
      "  253. 247.  53.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "    0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.  64.\n",
      "  252. 211.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "    0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0. 160.\n",
      "  252. 211.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "    0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0. 169.\n",
      "  252. 185.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "    0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0. 169.\n",
      "  252.  62.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "    0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "    0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "    0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "    0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "    0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "    0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "    0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "    0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.]]\n",
      "Test Accuracy: 1.0\n",
      "Time: 0.006363345000863774\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#Import MNIST working code\n",
    "\n",
    "import tinygrad\n",
    "import numpy as np\n",
    "import argparse\n",
    "import time\n",
    "#Boilerplate\n",
    "#Load Data\n",
    "##Struct Network\n",
    "#train\n",
    "#run\n",
    "\n",
    "#struct network\n",
    "from tinygrad.nn import Linear\n",
    "from tinygrad.tensor import Tensor\n",
    "from tinygrad.lazy import Device\n",
    "Device.DEFAULT = \"CPU\"\n",
    "\n",
    "\n",
    "\n",
    "class TinyDense:\n",
    "  def __init__(self):\n",
    "    self.l1 = Linear(784, 128, bias=False)\n",
    "    self.l2 = Linear(128, 10, bias=False)\n",
    "\n",
    "  def __call__(self, x):\n",
    "    x = self.l1(x)\n",
    "    x = x.leakyrelu()\n",
    "    x = self.l2(x)\n",
    "    return x.log_softmax()\n",
    "\n",
    "net = TinyDense()\n",
    "Tensor.training = True #boilerplatish?\n",
    "\n",
    "from tinygrad.nn.optim import SGD\n",
    "opt = SGD([net.l1.weight, net.l2.weight], lr=3e-4)\n",
    "\n",
    "from extra.datasets import fetch_mnist, fetch_cifar\n",
    "X_train, Y_train, X_test, Y_test = fetch_mnist()\n",
    "\n",
    "from extra.training import sparse_categorical_crossentropy  \n",
    "from tinygrad.state import safe_save, safe_load, get_state_dict, load_state_dict\n",
    "def cross_entropy(out, Y):\n",
    "  num_classes = out.shape[-1]\n",
    "  YY = Y.flatten().astype(np.int32)\n",
    "  y = np.zeros((YY.shape[0], num_classes), np.float32)\n",
    "  y[range(y.shape[0]),YY] = -1.0*num_classes\n",
    "  y = y.reshape(list(Y.shape)+[num_classes])\n",
    "  y = Tensor(y)\n",
    "  return out.mul(y).mean()\n",
    "\n",
    "#load model\n",
    "\n",
    "state_dict = safe_load(\"TinyDense.safetensors\")\n",
    "load_state_dict(net, state_dict)\n",
    "\n",
    "for step in range(8000):\n",
    "    #random sample batch??\n",
    "    samp = np.random.randint(0, X_train.shape[0], size=(128))\n",
    "    batch = Tensor(X_train[samp], requires_grad=True)\n",
    "    #labels for the same random sample? Batch of 64?\n",
    "    labels = Y_train[samp]\n",
    "    #fordward pass\n",
    "    out = net (batch)\n",
    "\n",
    "    #compute loss\n",
    "    loss = cross_entropy(out, labels)\n",
    "    #zero gradients\n",
    "    opt.zero_grad()\n",
    "    #backward   \n",
    "    loss.backward()\n",
    "    #update param\n",
    "    opt.step()\n",
    "\n",
    "    #calculate accuracy\n",
    "    pred = np.argmax(out.numpy(), axis=-1)\n",
    "    acc = (pred == labels).mean()\n",
    "    if acc >= 1:\n",
    "        break\n",
    "    if step % 100 == 0:\n",
    "        print(f'step{step} | Loss: {loss.numpy()} | Accuracy: {acc}')\n",
    "\n",
    "#save model\n",
    "state_dict = get_state_dict(net)\n",
    "safe_save(state_dict, \"TinyDense.safetensors\")\n",
    "\n",
    "\n",
    "#test model\n",
    "Tensor.training = False\n",
    "av_acc = 0 #reset acc\n",
    "st = time.perf_counter()\n",
    "print(X_test.shape)\n",
    "testamount = 1\n",
    "for step in range(testamount):\n",
    "    #test is just fordward?\n",
    "    samp = np.random.randint(0, X_test.shape[0], size=1)\n",
    "    batch = Tensor(X_test[samp], requires_grad=True)\n",
    "    #get labels\n",
    "    labels = Y_test[samp]\n",
    "    #forward pass\n",
    "    out = net(batch)\n",
    "  \n",
    "    pred = np.argmax(out.numpy(), axis=-1)\n",
    "    av_acc += (pred == labels).mean()\n",
    "    print(out.shape)\n",
    "    print(np.argmax(out.numpy()))\n",
    "    print(Y_test[samp])\n",
    "    print(batch.numpy())\n",
    " \n",
    "print(f\"Test Accuracy: {av_acc / testamount}\")\n",
    "print(f\"Time: {time.perf_counter() - st}\")\n",
    "#94% MNIST? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 3072)\n"
     ]
    }
   ],
   "source": [
    "#open up CIFAR\n",
    "X, Y = fetch_cifar(train=True)\n",
    "#reshape\n",
    "Xr = X.reshape(50000, -1)\n",
    "print(Xr.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TinyDense:\n",
    "  def __init__(self):\n",
    "    self.l1 = Linear(3072, 128, bias=False)\n",
    "    self.l2 = Linear(128, 10, bias=False)\n",
    "\n",
    "  def __call__(self, x):\n",
    "    x = self.l1(x)\n",
    "    x = x.leakyrelu()\n",
    "    x = self.l2(x)\n",
    "    return x.log_softmax()\n",
    "\n",
    "net = TinyDense()\n",
    "Tensor.training = True #boilerplatish?\n",
    "\n",
    "from tinygrad.nn.optim import SGD\n",
    "opt = SGD([net.l1.weight, net.l2.weight], lr=3e-3)\n",
    "\n",
    "from extra.datasets import fetch_mnist, fetch_cifar\n",
    "X_train, Y_train, X_test, Y_test = fetch_mnist()\n",
    "\n",
    "from extra.training import sparse_categorical_crossentropy  \n",
    "from tinygrad.state import safe_save, safe_load, get_state_dict, load_state_dict\n",
    "def cross_entropy(out, Y):\n",
    "  num_classes = out.shape[-1]\n",
    "  YY = Y.flatten().astype(np.int32)\n",
    "  y = np.zeros((YY.shape[0], num_classes), np.float32)\n",
    "  y[range(y.shape[0]),YY] = -1.0*num_classes\n",
    "  y = y.reshape(list(Y.shape)+[num_classes])\n",
    "  y = Tensor(y)\n",
    "  return out.mul(y).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step0 | Loss: 183.7943572998047 | Accuracy: 0.078125\n",
      "step100 | Loss: 56959924.0 | Accuracy: 0.140625\n",
      "step200 | Loss: 28365152.0 | Accuracy: 0.109375\n",
      "step300 | Loss: 17038890.0 | Accuracy: 0.1171875\n",
      "step400 | Loss: 8207320.0 | Accuracy: 0.078125\n",
      "step500 | Loss: 8522882.0 | Accuracy: 0.1328125\n",
      "step600 | Loss: 5506623.5 | Accuracy: 0.140625\n",
      "step700 | Loss: 2399960.75 | Accuracy: 0.1484375\n",
      "step800 | Loss: 2082001.0 | Accuracy: 0.21875\n",
      "step900 | Loss: 1874370.0 | Accuracy: 0.1875\n",
      "step1000 | Loss: 1470141.625 | Accuracy: 0.2265625\n",
      "step1100 | Loss: 843535.0 | Accuracy: 0.1796875\n",
      "step1200 | Loss: 929060.0 | Accuracy: 0.28125\n",
      "step1300 | Loss: 1124453.125 | Accuracy: 0.265625\n",
      "step1400 | Loss: 687603.4375 | Accuracy: 0.1796875\n",
      "step1500 | Loss: 730008.4375 | Accuracy: 0.2578125\n",
      "step1600 | Loss: 505249.71875 | Accuracy: 0.1875\n",
      "step1700 | Loss: 10449819.0 | Accuracy: 0.0859375\n",
      "step1800 | Loss: 5109804.5 | Accuracy: 0.1640625\n",
      "step1900 | Loss: 3291413.25 | Accuracy: 0.1171875\n",
      "step2000 | Loss: 1509549.0 | Accuracy: 0.2578125\n",
      "step2100 | Loss: 870009.4375 | Accuracy: 0.328125\n",
      "step2200 | Loss: 1465138.375 | Accuracy: 0.1640625\n",
      "step2300 | Loss: 935087.0 | Accuracy: 0.125\n",
      "step2400 | Loss: 516074.46875 | Accuracy: 0.2421875\n",
      "step2500 | Loss: 783544.4375 | Accuracy: 0.1953125\n",
      "step2600 | Loss: 599895.1875 | Accuracy: 0.3125\n",
      "step2700 | Loss: 1327319.875 | Accuracy: 0.140625\n",
      "step2800 | Loss: 1003612.4375 | Accuracy: 0.203125\n",
      "step2900 | Loss: 465542.09375 | Accuracy: 0.21875\n",
      "step3000 | Loss: 596793.4375 | Accuracy: 0.2734375\n",
      "step3100 | Loss: 353779.625 | Accuracy: 0.203125\n",
      "step3200 | Loss: 1277670.5 | Accuracy: 0.1328125\n",
      "step3300 | Loss: 627692.25 | Accuracy: 0.1640625\n",
      "step3400 | Loss: 181992.0 | Accuracy: 0.328125\n",
      "step3500 | Loss: 1002531.625 | Accuracy: 0.125\n",
      "step3600 | Loss: 186642.375 | Accuracy: 0.28125\n",
      "step3700 | Loss: 308553.09375 | Accuracy: 0.2265625\n",
      "step3800 | Loss: 221600.75 | Accuracy: 0.2734375\n",
      "step3900 | Loss: 140490.140625 | Accuracy: 0.2734375\n",
      "step4000 | Loss: 139693.15625 | Accuracy: 0.3203125\n",
      "step4100 | Loss: 345581.90625 | Accuracy: 0.265625\n",
      "step4200 | Loss: 134122.734375 | Accuracy: 0.296875\n",
      "step4300 | Loss: 480951.09375 | Accuracy: 0.2890625\n",
      "step4400 | Loss: 270181.03125 | Accuracy: 0.234375\n",
      "step4500 | Loss: 124652.578125 | Accuracy: 0.3359375\n",
      "step4600 | Loss: 280818.34375 | Accuracy: 0.2265625\n",
      "step4700 | Loss: 101623.9375 | Accuracy: 0.3125\n",
      "step4800 | Loss: 200059.046875 | Accuracy: 0.3046875\n",
      "step4900 | Loss: 166865.96875 | Accuracy: 0.296875\n",
      "step5000 | Loss: 192271.359375 | Accuracy: 0.1640625\n",
      "step5100 | Loss: 168677.8125 | Accuracy: 0.265625\n",
      "step5200 | Loss: 220279.859375 | Accuracy: 0.3046875\n",
      "step5300 | Loss: 146402.96875 | Accuracy: 0.28125\n",
      "step5400 | Loss: 264648.15625 | Accuracy: 0.21875\n",
      "step5500 | Loss: 130636.1796875 | Accuracy: 0.328125\n",
      "step5600 | Loss: 95292.3515625 | Accuracy: 0.2109375\n",
      "step5700 | Loss: 130181.2890625 | Accuracy: 0.21875\n",
      "step5800 | Loss: 189109.453125 | Accuracy: 0.28125\n",
      "step5900 | Loss: 127876.375 | Accuracy: 0.2890625\n",
      "step6000 | Loss: 160787.171875 | Accuracy: 0.2578125\n",
      "step6100 | Loss: 154495.71875 | Accuracy: 0.1953125\n",
      "step6200 | Loss: 108949.4296875 | Accuracy: 0.234375\n",
      "step6300 | Loss: 66695.4609375 | Accuracy: 0.3359375\n",
      "step6400 | Loss: 152892.78125 | Accuracy: 0.2734375\n",
      "step6500 | Loss: 94989.2890625 | Accuracy: 0.2734375\n",
      "step6600 | Loss: 251588.046875 | Accuracy: 0.25\n",
      "step6700 | Loss: 118059.3046875 | Accuracy: 0.3828125\n",
      "step6800 | Loss: 155880.5 | Accuracy: 0.2890625\n",
      "step6900 | Loss: 198835.234375 | Accuracy: 0.203125\n",
      "step7000 | Loss: 61586.2890625 | Accuracy: 0.2578125\n",
      "step7100 | Loss: 112681.6796875 | Accuracy: 0.296875\n",
      "step7200 | Loss: 147936.125 | Accuracy: 0.2265625\n",
      "step7300 | Loss: 57175.54296875 | Accuracy: 0.359375\n",
      "step7400 | Loss: 290418.84375 | Accuracy: 0.2421875\n",
      "step7500 | Loss: 67176.9609375 | Accuracy: 0.234375\n",
      "step7600 | Loss: 123796.7734375 | Accuracy: 0.21875\n",
      "step7700 | Loss: 73911.6484375 | Accuracy: 0.2109375\n",
      "step7800 | Loss: 63190.99609375 | Accuracy: 0.3125\n",
      "step7900 | Loss: 117331.7265625 | Accuracy: 0.21875\n"
     ]
    }
   ],
   "source": [
    "for step in range(8000):\n",
    "    #random sample batch??\n",
    "    samp = np.random.randint(0, Xr.shape[0], size=(64))\n",
    "    batch = Tensor(Xr[samp], requires_grad=True)\n",
    "    #labels for the same random sample? Batch of 64?\n",
    "    labels = Y[samp]\n",
    "    #fordward pass\n",
    "    out = net (batch)\n",
    "\n",
    "    #compute loss\n",
    "    loss = cross_entropy(out, labels)\n",
    "    #zero gradients\n",
    "    opt.zero_grad()\n",
    "    #backward   \n",
    "    loss.backward()\n",
    "    #update param\n",
    "    opt.step()\n",
    "\n",
    "    #calculate accuracy\n",
    "    pred = np.argmax(out.numpy(), axis=-1)\n",
    "    acc = (pred == labels).mean()\n",
    "    if acc >= 1:\n",
    "        break\n",
    "    if step % 100 == 0:\n",
    "        print(f'step{step} | Loss: {loss.numpy()} | Accuracy: {acc}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
